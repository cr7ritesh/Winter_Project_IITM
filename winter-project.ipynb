{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10282225,"sourceType":"datasetVersion","datasetId":6318067}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install pymupdf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T01:38:19.889136Z","iopub.execute_input":"2025-01-07T01:38:19.889367Z","iopub.status.idle":"2025-01-07T01:38:30.928568Z","shell.execute_reply.started":"2025-01-07T01:38:19.889341Z","shell.execute_reply":"2025-01-07T01:38:30.927389Z"}},"outputs":[{"name":"stdout","text":"Collecting pymupdf\n  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nDownloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf\nSuccessfully installed pymupdf-1.25.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom transformers import pipeline\nimport fitz  # PyMuPDF\nfrom PIL import Image\nimport re\nimport pytesseract\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom fuzzywuzzy import process\n# from pdf2image import convert_from_path","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T01:38:30.931040Z","iopub.execute_input":"2025-01-07T01:38:30.931356Z","iopub.status.idle":"2025-01-07T01:38:48.546620Z","shell.execute_reply.started":"2025-01-07T01:38:30.931325Z","shell.execute_reply":"2025-01-07T01:38:48.545817Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T01:38:48.547912Z","iopub.execute_input":"2025-01-07T01:38:48.548786Z","iopub.status.idle":"2025-01-07T01:38:48.641471Z","shell.execute_reply.started":"2025-01-07T01:38:48.548720Z","shell.execute_reply":"2025-01-07T01:38:48.640908Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# # Example paragraph\n# text = \"\"\"\n# Section 319 Cr.P.C. contemplates a situation where the evidence adduced by the prosecution for Respondent No.3-G. Sambiah on 20th June 1984\n# \"\"\"\n\n# # Step 1: Perform Named Entity Recognition (NER)\n# ner_pipeline = pipeline(\"ner\", grouped_entities=True, model=\"MHGanainy/roberta-base-legal-multi-downstream-indian-ner\", device = 0, aggregation_strategy=\"simple\")\n# entities = ner_pipeline(text)\n\n# # Display extracted entities\n# print(\"Extracted Entities:\")\n# for entity in entities:\n#     print(f\"Entity: {entity['word']}, Type: {entity['entity_group']}\")\n\n# # Step 2: Apply Question-Answering (QA) model using extracted entities\n# qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", device = 0)\n\n# # Define a list of questions based on extracted entities\n# questions = [\n#     f\"What is the role of {entity['word']}?\" for entity in entities if entity['entity_group'] == \"PER\"\n# ] + [\n#     f\"Where is {entity['word']} located?\" for entity in entities if entity['entity_group'] == \"PER\"\n# ] + [\n#     f\"When did the study take place?\" if any(entity['entity_group'] == \"DATE\" for entity in entities) else \"\"\n# ]\n\n# print(questions)\n\n# # Remove empty questions\n# questions = [q for q in questions if q]\n\n# # Perform QA\n# print(\"\\nQuestion-Answering Results:\")\n# for question in questions:\n#     result = qa_pipeline(question=question, context=text)\n#     print(f\"Q: {question}\")\n#     print(f\"A: {result['answer']}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T00:56:10.026845Z","iopub.execute_input":"2025-01-07T00:56:10.027109Z","iopub.status.idle":"2025-01-07T00:56:10.031880Z","shell.execute_reply.started":"2025-01-07T00:56:10.027084Z","shell.execute_reply":"2025-01-07T00:56:10.030936Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Step 1: Define Paths\nINPUT_PDF_PATH = \"/kaggle/input/supreme-court-judgements/Pramod_Suryabhan_Pawar_vs_The_State_Of_Maharashtra_on_21_August_2019.PDF\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:01:36.709382Z","iopub.execute_input":"2025-01-07T02:01:36.710046Z","iopub.status.idle":"2025-01-07T02:01:36.713673Z","shell.execute_reply.started":"2025-01-07T02:01:36.710011Z","shell.execute_reply":"2025-01-07T02:01:36.712883Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Step 2: Configure OCR\ndef extract_text_from_pdf(pdf_path):\n    # Open the PDF file\n    doc = fitz.open(pdf_path)\n\n    print('output fine!')\n\n    # Iterate over each page\n    text = \"\"\n    for page_num in range(len(doc)):\n        page = doc.load_page(page_num)\n\n        # Convert page to image\n        pix = page.get_pixmap()\n        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n\n        print('we are here', page_num)\n        # OCR the image\n        page_text = pytesseract.image_to_string(img, lang = 'eng')\n        text += f\"--- Page {page_num + 1} ---\\n{page_text}\\n\"\n\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T01:38:48.649814Z","iopub.execute_input":"2025-01-07T01:38:48.650367Z","iopub.status.idle":"2025-01-07T01:38:48.657483Z","shell.execute_reply.started":"2025-01-07T01:38:48.650327Z","shell.execute_reply":"2025-01-07T01:38:48.656712Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Step 3: Save Text to File\ndef save_text_to_file(text, file_path):\n    \"\"\"Save extracted text to a temporary file.\"\"\"\n    with open(file_path, 'w', encoding='utf-8') as file:\n        file.write(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T01:39:02.001484Z","iopub.execute_input":"2025-01-07T01:39:02.002170Z","iopub.status.idle":"2025-01-07T01:39:02.006283Z","shell.execute_reply.started":"2025-01-07T01:39:02.002133Z","shell.execute_reply":"2025-01-07T01:39:02.005271Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Load NER model\n\n# nice\nner_model = pipeline(\"ner\", model=\"MHGanainy/roberta-base-legal-multi-downstream-indian-ner\", device = 0, aggregation_strategy=\"simple\")\n\n# testing\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T01:39:02.358145Z","iopub.execute_input":"2025-01-07T01:39:02.358782Z","iopub.status.idle":"2025-01-07T01:39:18.052427Z","shell.execute_reply.started":"2025-01-07T01:39:02.358750Z","shell.execute_reply":"2025-01-07T01:39:18.051688Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"286514919ca74dcbadb83a2d4ca1339e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dda8e35179374761b6e2e62690584d9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19bf0a2a7d214ba6aae987ea02af634a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"550f1f7c20474f91935969756d2ab84d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fed9ae0576f846a680c5dca20544bc6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8c11deca39a43da9e08b7772d237d66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/958 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7b751b0a41943e791a8dca465ab6217"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Step 4: Load the QA Models\n# qa_model = pipeline(\"question-answering\", model=\"allenai/longformer-large-4096-finetuned-triviaqa\", device = 0)\nqa_model = pipeline(\"question-answering\", model=\"atharvamundada99/bert-large-question-answering-finetuned-legal\", device = 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T01:39:19.448938Z","iopub.execute_input":"2025-01-07T01:39:19.449299Z","iopub.status.idle":"2025-01-07T01:39:27.589385Z","shell.execute_reply.started":"2025-01-07T01:39:19.449258Z","shell.execute_reply":"2025-01-07T01:39:27.588531Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a88c43845164df39aa1958a1836695b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"877142be55c5458a9e0d83c35ede5765"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32c3547628cb41aea846f6666ef2592f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a6345b88baa4c24a282b6ee286b650c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b67b2c00bbea4d0fa70e15e4ed893952"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Step 5: QA Functionality\ndef ask_questions(context, questions):\n    \"\"\"Answer questions based on the given context using the QA model.\"\"\"\n    print(\"\\n--- QA Results ---\")\n    answers = []\n    for idx, question in enumerate(questions):\n        result = qa_model(question=question, context=context)\n        # print(f\"Q: {question}\\nA: {result['answer']}\\n\")\n        print('question ', idx + 3, ' done!')\n        answers.append(result['answer'])\n    return answers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T01:39:29.314132Z","iopub.execute_input":"2025-01-07T01:39:29.314452Z","iopub.status.idle":"2025-01-07T01:39:29.319528Z","shell.execute_reply.started":"2025-01-07T01:39:29.314423Z","shell.execute_reply":"2025-01-07T01:39:29.318576Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def extract_entities(text):\n    \"\"\"Extract named entities from text using the NER model.\"\"\"\n    return ner_model(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T01:39:30.238547Z","iopub.execute_input":"2025-01-07T01:39:30.239176Z","iopub.status.idle":"2025-01-07T01:39:30.243225Z","shell.execute_reply.started":"2025-01-07T01:39:30.239139Z","shell.execute_reply":"2025-01-07T01:39:30.242287Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def get_bleu_score(actual, predicted):\n\n    sum_bleu = 0\n    for ref, pred in zip(actual, predictions):\n        # Tokenize references and predictions\n        ref_tokens = [ref.split()]  # List of tokenized references\n        pred_tokens = pred.split()            # Tokenized prediction\n\n        # print(ref_tokens, pred_tokens)\n    \n        # Compute BLEU score\n        bleu_score = sentence_bleu(ref_tokens, pred_tokens)\n        # print(\"Bleu value without smoothing:\", bleu_score_no_smoothing)\n\n        # print('Bleu value:', bleu_score)\n\n        sum_bleu += bleu_score\n    return (sum_bleu / len(actual))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T01:39:31.966156Z","iopub.execute_input":"2025-01-07T01:39:31.966588Z","iopub.status.idle":"2025-01-07T01:39:31.975040Z","shell.execute_reply.started":"2025-01-07T01:39:31.966521Z","shell.execute_reply":"2025-01-07T01:39:31.974010Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"document_text = extract_text_from_pdf(INPUT_PDF_PATH)\n# save_text_to_file(document_text, TEMP_TEXT_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:01:42.789200Z","iopub.execute_input":"2025-01-07T02:01:42.789841Z","iopub.status.idle":"2025-01-07T02:02:02.945298Z","shell.execute_reply.started":"2025-01-07T02:01:42.789805Z","shell.execute_reply":"2025-01-07T02:02:02.944379Z"}},"outputs":[{"name":"stdout","text":"output fine!\nwe are here 0\nwe are here 1\nwe are here 2\nwe are here 3\nwe are here 4\nwe are here 5\nwe are here 6\nwe are here 7\nwe are here 8\nwe are here 9\nwe are here 10\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"document_text = re.sub(r\"^Author: .*?$\", \"\", document_text, flags=re.MULTILINE) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:02:02.946989Z","iopub.execute_input":"2025-01-07T02:02:02.947277Z","iopub.status.idle":"2025-01-07T02:02:02.951621Z","shell.execute_reply.started":"2025-01-07T02:02:02.947250Z","shell.execute_reply":"2025-01-07T02:02:02.950706Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Run NER\nner_res = extract_entities(document_text)\n\nfinal_ner_res = []\nprint(\"\\n--- NER Results ---\")\nfor entity in ner_res:\n    if entity['score'] >= 0.99:\n        if entity['entity_group'] == 'PETITIONER' or entity['entity_group'] == 'RESPONDENT' or entity['entity_group'] == 'JUDGE':\n            print(f\"Entity: {entity['word']} - Label: {entity['entity_group']}\\n\")\n            final_ner_res.append({\"entity\": entity['word'], \"label\": entity['entity_group']})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:02:02.952836Z","iopub.execute_input":"2025-01-07T02:02:02.953174Z","iopub.status.idle":"2025-01-07T02:02:03.048599Z","shell.execute_reply.started":"2025-01-07T02:02:02.953137Z","shell.execute_reply":"2025-01-07T02:02:03.047781Z"}},"outputs":[{"name":"stdout","text":"\n--- NER Results ---\nEntity: Pramod Suryabhan Pawar - Label: PETITIONER\n\nEntity:  State Of Maharashtra - Label: RESPONDENT\n\nEntity:  Indira Banerjee - Label: JUDGE\n\nEntity:  Dhananjaya Y Chandrachud - Label: JUDGE\n\nEntity: Pramod Suryahan Pawar - Label: PETITIONER\n\nEntity:  State of Maharashtra - Label: RESPONDENT\n\nEntity:  Dhananjaya ¥ Chandrachud - Label: JUDGE\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Raw NER results\nner_results = final_ner_res\n\n# Combine and clean NER results\ndef clean_ner_results(ner_results):\n    entities_by_label = {}\n    \n    # Group entities by label\n    for result in ner_results:\n        label = result[\"label\"]\n        entity = result[\"entity\"].strip()\n        if label not in entities_by_label:\n            entities_by_label[label] = []\n        entities_by_label[label].append(entity)\n\n    # Post-process Respondent and Petitioner\n    def select_longest(entities):\n        if not entities:\n            return None\n        # Select the longest unique entity\n        return max(set(entities), key=len)\n\n    # Post-process judges\n    def process_judges(judges):\n        valid_judges = []\n        for judge in judges:\n            # Filter out short entities or fragments\n            if len(judge.split()) > 1 and len(judge) > 2:\n                # Normalize case to handle duplicate entries like \"K.S. Radhakrishnan\" and \"K.S. RADHAKRISHNAN\"\n                normalized_name = judge.lower()\n                \n                # Check if this normalized name is already in valid_judges (case insensitive comparison)\n                if not any(existing.lower() == normalized_name for existing in valid_judges):\n                    valid_judges.append(judge)\n        # Deduplicate (case-insensitive)\n        return list(set(valid_judges))\n\n    # Process entities by label\n    for label, entities in entities_by_label.items():\n        if label in [\"PETITIONER\", \"RESPONDENT\"]:\n            # Select the longest entity for these labels\n            entities_by_label[label] = [select_longest(entities)]\n        elif label == \"JUDGE\":\n            entities_by_label[label] = process_judges(entities)\n        else:\n            # Deduplicate for other labels\n            entities_by_label[label] = list(set(entities))\n\n    return entities_by_label\n\n# Cleaned results\ncleaned_results = clean_ner_results(ner_results)\n\n# Output\n# for label, entities in cleaned_results.items():\n#     print(f\"{label}: {entities}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:02:15.719855Z","iopub.execute_input":"2025-01-07T02:02:15.720448Z","iopub.status.idle":"2025-01-07T02:02:15.728320Z","shell.execute_reply.started":"2025-01-07T02:02:15.720411Z","shell.execute_reply":"2025-01-07T02:02:15.727375Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"lst = list(cleaned_results.values())\n# print(lst)\n\nfinal_lst = [', '.join(item) for item in lst]\nfinal_lst","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:02:18.850223Z","iopub.execute_input":"2025-01-07T02:02:18.850941Z","iopub.status.idle":"2025-01-07T02:02:18.856560Z","shell.execute_reply.started":"2025-01-07T02:02:18.850907Z","shell.execute_reply":"2025-01-07T02:02:18.855612Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"['Pramod Suryabhan Pawar',\n 'State Of Maharashtra',\n 'Indira Banerjee, Dhananjaya ¥ Chandrachud, Dhananjaya Y Chandrachud']"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# Define sample questions for QA\nquestions = [\n    \"Who is the petitioner/appellant?\",\n    \"Who is the respondent?\",\n    \"Which bench/judges delivered the judgment?\",\n    \"What is the final verdict?\",\n    \"What is the legal provision cited?\",\n    \"What was the primary legal issue addressed in this judgment?\"\n]\n\npredictions = ask_questions(document_text, questions[3:])\npredictions = final_lst + predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:02:35.981497Z","iopub.execute_input":"2025-01-07T02:02:35.982336Z","iopub.status.idle":"2025-01-07T02:02:44.245066Z","shell.execute_reply.started":"2025-01-07T02:02:35.982301Z","shell.execute_reply":"2025-01-07T02:02:44.244122Z"}},"outputs":[{"name":"stdout","text":"\n--- QA Results ---\nquestion  3  done!\nquestion  4  done!\nquestion  5  done!\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"predictions += ask_questions(document_text[:100], ['What was the date of the judgment?'])\npredictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:02:47.417219Z","iopub.execute_input":"2025-01-07T02:02:47.417594Z","iopub.status.idle":"2025-01-07T02:02:47.452019Z","shell.execute_reply.started":"2025-01-07T02:02:47.417561Z","shell.execute_reply":"2025-01-07T02:02:47.451177Z"}},"outputs":[{"name":"stdout","text":"\n--- QA Results ---\nquestion  3  done!\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"['Pramod Suryabhan Pawar',\n 'State Of Maharashtra',\n 'Indira Banerjee, Dhananjaya ¥ Chandrachud, Dhananjaya Y Chandrachud',\n 'Court rejected the application',\n '7 Section 482',\n 'consent',\n '21\\nAugust, 2019']"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"answers = ['Pramod Suryabhan Pawar',\n          'State Of Maharashtra',\n          'Indira Banerjee, Dhananjaya Y Chandrachud',\n          'no offence',\n          'Section 482, Section 375',\n           'sexual consent',\n          '21 August, 2019']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:06:27.289384Z","iopub.execute_input":"2025-01-07T02:06:27.290180Z","iopub.status.idle":"2025-01-07T02:06:27.294049Z","shell.execute_reply.started":"2025-01-07T02:06:27.290143Z","shell.execute_reply":"2025-01-07T02:06:27.293210Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"get_bleu_score(answers, predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T02:06:28.228399Z","iopub.execute_input":"2025-01-07T02:06:28.229253Z","iopub.status.idle":"2025-01-07T02:06:28.235393Z","shell.execute_reply.started":"2025-01-07T02:06:28.229217Z","shell.execute_reply":"2025-01-07T02:06:28.234550Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 4-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0.6428172014717191"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}